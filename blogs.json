{"status":"ok","feed":{"url":"https://medium.com/feed/@Amruta1311","title":"Stories by Amruta Mulay on Medium","link":"https://medium.com/@amruta1311?source=rss-724f1c6debbf------2","author":"","description":"Stories by Amruta Mulay on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*X2E5Dj73UHrB1qTu3LEo2A.png"},"items":[{"title":"Radial Basis Function Neural Network","pubDate":"2021-01-03 14:55:30","link":"https://amruta1311.medium.com/radial-basis-function-neural-network-fa1d769cefb0?source=rss-724f1c6debbf------2","guid":"https://medium.com/p/fa1d769cefb0","author":"Amruta Mulay","thumbnail":"https://cdn-images-1.medium.com/max/733/1*lGMh2GesRnCQb93v6N1rdw.jpeg","description":"\n<p>The RBFNN consists of an input vector succeeded by a layer of the radial basis function neurons and the resultant output layer with one node per group. Categorization is executed based on the measurement of the input data\u2019s resemblance with the data points of the training dataset. Each of the neurons store a prototype which will be one of the samples from the training\u00a0set.</p>\n<p>When we classify a new n-dimensional input vector,the euclidean distance between the input and the prototype is computed for each neuron. For instance, if there are two categories (say category A and B) present in our training set then we calculate the closeness of our input data with both the given groups by means of their euclidean distance. If the distance measured between the input data and the category A is smaller as compared to the distance between the input data and category B, then the input data is classified as class\u00a0A.</p>\n<p>Every neuron of RBF compares the input data with the prototype of the samples in the training dataset. The resultant value is a measure of similarity between the range of 0 and 1. When the input data is similar to its prototype then the resultant value of the RBF neuron will be 1 and the euclidean distance between the two will exponentially dive to\u00a0zero.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/733/1*lGMh2GesRnCQb93v6N1rdw.jpeg\"><figcaption>Radial Basis Neural\u00a0Network</figcaption></figure><blockquote><strong>Applications of Radial Basis Function Neural\u00a0Network</strong></blockquote>\n<ul>\n<li>\n<strong><em>Power Restoration:</em></strong> There is a possibility of an over-voltage power cut that may happen due to the transformation switching. The over-voltages may harm some equipment as well as cause a delay in the restorations of the power systems. A developed RBFNN model gives the equivalent attributes as the input to the model. It trains for the worst case situation that may occur like switching angles or the remainder flux. The model is then tested for such cases. It ensures the power-cut that happens to the supply that connects the most number of houses is restored first and eventually it goes on until the supply that impacts only one house is restored in the\u00a0last.</li>\n<li>\n<strong><em>Mechanical Fault Diagnosis of a Gearbox:</em></strong> We have had a brief analysis over how the RBFNN is helpful for the pattern classification and contributes to a quick learning pace along with the capability to map in a non-linear fashion. These features help in employing the fault diagnosis. The gearbox is a very frequently used equipment in the field of engineering. By means of a trained RBFNN model, we can ensure that the diagnosis of the mechanical faults can take place correctly.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fa1d769cefb0\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>The RBFNN consists of an input vector succeeded by a layer of the radial basis function neurons and the resultant output layer with one node per group. Categorization is executed based on the measurement of the input data\u2019s resemblance with the data points of the training dataset. Each of the neurons store a prototype which will be one of the samples from the training\u00a0set.</p>\n<p>When we classify a new n-dimensional input vector,the euclidean distance between the input and the prototype is computed for each neuron. For instance, if there are two categories (say category A and B) present in our training set then we calculate the closeness of our input data with both the given groups by means of their euclidean distance. If the distance measured between the input data and the category A is smaller as compared to the distance between the input data and category B, then the input data is classified as class\u00a0A.</p>\n<p>Every neuron of RBF compares the input data with the prototype of the samples in the training dataset. The resultant value is a measure of similarity between the range of 0 and 1. When the input data is similar to its prototype then the resultant value of the RBF neuron will be 1 and the euclidean distance between the two will exponentially dive to\u00a0zero.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/733/1*lGMh2GesRnCQb93v6N1rdw.jpeg\"><figcaption>Radial Basis Neural\u00a0Network</figcaption></figure><blockquote><strong>Applications of Radial Basis Function Neural\u00a0Network</strong></blockquote>\n<ul>\n<li>\n<strong><em>Power Restoration:</em></strong> There is a possibility of an over-voltage power cut that may happen due to the transformation switching. The over-voltages may harm some equipment as well as cause a delay in the restorations of the power systems. A developed RBFNN model gives the equivalent attributes as the input to the model. It trains for the worst case situation that may occur like switching angles or the remainder flux. The model is then tested for such cases. It ensures the power-cut that happens to the supply that connects the most number of houses is restored first and eventually it goes on until the supply that impacts only one house is restored in the\u00a0last.</li>\n<li>\n<strong><em>Mechanical Fault Diagnosis of a Gearbox:</em></strong> We have had a brief analysis over how the RBFNN is helpful for the pattern classification and contributes to a quick learning pace along with the capability to map in a non-linear fashion. These features help in employing the fault diagnosis. The gearbox is a very frequently used equipment in the field of engineering. By means of a trained RBFNN model, we can ensure that the diagnosis of the mechanical faults can take place correctly.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=fa1d769cefb0\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["rbf","racial-bias","categorization","neurons","neural-networks"]},{"title":"Convolutional Neural Networks (CNN)","pubDate":"2021-01-03 14:09:40","link":"https://amruta1311.medium.com/convolutional-neural-networks-cnn-2b0021491d39?source=rss-724f1c6debbf------2","guid":"https://medium.com/p/2b0021491d39","author":"Amruta Mulay","thumbnail":"https://cdn-images-1.medium.com/max/893/1*vRVKIAvBnqtb2B6N3dui2w.jpeg","description":"\n<p>Unlike the standard two dimensional array, these neural networks are a three dimensional ordering of the neurons. The very first layer is termed as the convolutional layer. Every neuron that is present in this layer operates on the data that comes from the small part of the visual field.<br>All the input attributes are taken in a group wise manner similar to a filter. The model interprets the images in segments and is able to process these operations a number of times so as to complete the entire image processing. The main function of processing involves the transformation of the image from the RGB or HSI scale to the greyscale. Furthermore, any modification in the values of the pixels help in identifying the edges and then the images are grouped into distinct categories.</p>\n<p>The propagation followed is in one direction in which the CNN model may comprise one or more convolutional layers. This is followed by pooling whose operation is to lessen the spatial size of the information representation to decrease the number of the measurable factors and computations in our model. Then the output of the convolutional layers is given to a fully connected neural network that categorizes the images as shown in the below figure. We use the filters to draw out the specific parts of the image. In the multi-layer perceptron, these inputs are multiplied with their respective weights and fed to the activation function. The convolution uses the rectified linear unit function and the multi-layer perceptron makes the use of non linear activation functions followed by the softmax function. Even though the design of the convolution network might be a bit complicated, it uses less parameters to train itself compared to a fully connected layer.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/893/1*vRVKIAvBnqtb2B6N3dui2w.jpeg\"><figcaption>Convolutional Neural\u00a0Network</figcaption></figure><blockquote><strong>Applications of Convolutional Neural\u00a0Network</strong></blockquote>\n<ul>\n<li>\n<strong><em>Deciphering the Facial Recognition: </em></strong>We follow certain steps to decode facial recognition along with some major components. The first step involves the identification of the face present in the image. The second step focuses on the features of the face excluding the external factors like pose, light, disturbance, angle, etc. After the identification of the unique features, we compare the collected information with the existing training data in the database to complement the face with its\u00a0name.</li>\n<li>\n<strong><em>Comprehension of the Climate:</em></strong> They help in playing a very important role in order to fight against the climatic changes. It is able to analyse the reasons on why we are able to see such drastic changes in the climate and what can be done so as to damp this effect. This helps in providing the social as well as scientific insights.</li>\n<li>\n<strong><em>Medical Image Computation:</em></strong> Medical images comprise a lot of data evaluation that stimulates from the original image recognition. The classification of medical images that are done by the CNN model helps in pointing out the inconsistencies found on the X-rays or the MRI images through a lot more precision as compared with the human eye. The model is able to find the differences between the given sequence of images, thus providing the basis for further predictive analysis.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2b0021491d39\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>Unlike the standard two dimensional array, these neural networks are a three dimensional ordering of the neurons. The very first layer is termed as the convolutional layer. Every neuron that is present in this layer operates on the data that comes from the small part of the visual field.<br>All the input attributes are taken in a group wise manner similar to a filter. The model interprets the images in segments and is able to process these operations a number of times so as to complete the entire image processing. The main function of processing involves the transformation of the image from the RGB or HSI scale to the greyscale. Furthermore, any modification in the values of the pixels help in identifying the edges and then the images are grouped into distinct categories.</p>\n<p>The propagation followed is in one direction in which the CNN model may comprise one or more convolutional layers. This is followed by pooling whose operation is to lessen the spatial size of the information representation to decrease the number of the measurable factors and computations in our model. Then the output of the convolutional layers is given to a fully connected neural network that categorizes the images as shown in the below figure. We use the filters to draw out the specific parts of the image. In the multi-layer perceptron, these inputs are multiplied with their respective weights and fed to the activation function. The convolution uses the rectified linear unit function and the multi-layer perceptron makes the use of non linear activation functions followed by the softmax function. Even though the design of the convolution network might be a bit complicated, it uses less parameters to train itself compared to a fully connected layer.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/893/1*vRVKIAvBnqtb2B6N3dui2w.jpeg\"><figcaption>Convolutional Neural\u00a0Network</figcaption></figure><blockquote><strong>Applications of Convolutional Neural\u00a0Network</strong></blockquote>\n<ul>\n<li>\n<strong><em>Deciphering the Facial Recognition: </em></strong>We follow certain steps to decode facial recognition along with some major components. The first step involves the identification of the face present in the image. The second step focuses on the features of the face excluding the external factors like pose, light, disturbance, angle, etc. After the identification of the unique features, we compare the collected information with the existing training data in the database to complement the face with its\u00a0name.</li>\n<li>\n<strong><em>Comprehension of the Climate:</em></strong> They help in playing a very important role in order to fight against the climatic changes. It is able to analyse the reasons on why we are able to see such drastic changes in the climate and what can be done so as to damp this effect. This helps in providing the social as well as scientific insights.</li>\n<li>\n<strong><em>Medical Image Computation:</em></strong> Medical images comprise a lot of data evaluation that stimulates from the original image recognition. The classification of medical images that are done by the CNN model helps in pointing out the inconsistencies found on the X-rays or the MRI images through a lot more precision as compared with the human eye. The model is able to find the differences between the given sequence of images, thus providing the basis for further predictive analysis.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2b0021491d39\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["convolutional-neural-net","pooling","flattening","relu","neural-networks"]},{"title":"Feed-Forward Neural Networks","pubDate":"2021-01-03 14:01:29","link":"https://amruta1311.medium.com/feed-forward-neural-networks-f9266675c67f?source=rss-724f1c6debbf------2","guid":"https://medium.com/p/f9266675c67f","author":"Amruta Mulay","thumbnail":"https://cdn-images-1.medium.com/max/692/1*m-ywLrZEI_JjSo73nu_ayw.jpeg","description":"\n<p>The feed forward neural networks are also termed as the multi-layer perceptrons. In this type of neural networks, the observed movement of data is unidirectional. It may consist of either zero, one or many hidden layers. When we use them, they are fast in their operation. But while training the data, they may take a while. The nodes of this network do not form a cycle. Moreover, all the nodes in a particular network are connected with the nodes of the next layer. we may say that they are fully connected. There are no back-loops present. In order to minimise the error in the prediction, we employ the back-propagation algorithm so as to update the weights and\u00a0biases.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/692/1*m-ywLrZEI_JjSo73nu_ayw.jpeg\"><figcaption>Feed-Forward Neural\u00a0Network</figcaption></figure><p>The back-propagation algorithm focuses on minimising the error rate between the predicted output and the actual result by means of adjusting the values of the weights and biases. The final weights that help it provide the optimal result are regarded to be the solution. Thus, we effectively train our model using the chain rule. After each forward pass that is implemented, we perform a backward pass that adjusts the parameters.</p>\n<blockquote><strong><em>Applications of Feed-forward Neural\u00a0Networks</em></strong></blockquote>\n<ul>\n<li>\n<strong><em>Computer Vision:</em></strong> With a good number of training examples available, the hierarchical feed-forward neural networks are able to form the feature learning tool to build the visual recognition models that can be implemented across various\u00a0domains.</li>\n<li>\n<strong><em>Speech Recognition:</em></strong> This is designed as a three layer system. The first layer analyzes and classifies a set of speech attributes that are assigned to it. The middle layer is responsible for building the speech matrix from the classification scores that have been developed by the first layer. Then comes the third or the last layer that evaluates this speech matrix so as to predict the output for the\u00a0model.</li>\n<li>\n<strong><em>Handwritten Character Recognition:</em></strong> The training set provided to the model will be a bitmap pattern of the handwritten characters as the input to the model. The right letter or digit is the output that we\u00a0desire.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f9266675c67f\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<p>The feed forward neural networks are also termed as the multi-layer perceptrons. In this type of neural networks, the observed movement of data is unidirectional. It may consist of either zero, one or many hidden layers. When we use them, they are fast in their operation. But while training the data, they may take a while. The nodes of this network do not form a cycle. Moreover, all the nodes in a particular network are connected with the nodes of the next layer. we may say that they are fully connected. There are no back-loops present. In order to minimise the error in the prediction, we employ the back-propagation algorithm so as to update the weights and\u00a0biases.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/692/1*m-ywLrZEI_JjSo73nu_ayw.jpeg\"><figcaption>Feed-Forward Neural\u00a0Network</figcaption></figure><p>The back-propagation algorithm focuses on minimising the error rate between the predicted output and the actual result by means of adjusting the values of the weights and biases. The final weights that help it provide the optimal result are regarded to be the solution. Thus, we effectively train our model using the chain rule. After each forward pass that is implemented, we perform a backward pass that adjusts the parameters.</p>\n<blockquote><strong><em>Applications of Feed-forward Neural\u00a0Networks</em></strong></blockquote>\n<ul>\n<li>\n<strong><em>Computer Vision:</em></strong> With a good number of training examples available, the hierarchical feed-forward neural networks are able to form the feature learning tool to build the visual recognition models that can be implemented across various\u00a0domains.</li>\n<li>\n<strong><em>Speech Recognition:</em></strong> This is designed as a three layer system. The first layer analyzes and classifies a set of speech attributes that are assigned to it. The middle layer is responsible for building the speech matrix from the classification scores that have been developed by the first layer. Then comes the third or the last layer that evaluates this speech matrix so as to predict the output for the\u00a0model.</li>\n<li>\n<strong><em>Handwritten Character Recognition:</em></strong> The training set provided to the model will be a bitmap pattern of the handwritten characters as the input to the model. The right letter or digit is the output that we\u00a0desire.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f9266675c67f\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["feed-forward-networks","neural-networks","application","multilayer-perceptron","backpropagation"]},{"title":"The Essence of  Neural Networks","pubDate":"2021-01-02 07:40:28","link":"https://amruta1311.medium.com/the-essence-of-neural-networks-f8a7f6153736?source=rss-724f1c6debbf------2","guid":"https://medium.com/p/f8a7f6153736","author":"Amruta Mulay","thumbnail":"https://cdn-images-1.medium.com/max/692/1*87CD2W7b8mhTYKk1Hwj5YA.jpeg","description":"\n<h3>The Essence of Neural\u00a0Networks</h3>\n<blockquote><strong><em>Abstract</em></strong></blockquote>\n<p>The world comprises many complex, unstructured and enormous amounts of data to compute so as to perform a network of operations over them. Humans are incapable of extricating information from compound structures. If we design a mathematical model that recreates the way a human brain is able to analyze and work, we come up with a perfect computing system that is able to solve the complicated set of data. We aim to understand the essence of the working of neural networks. They employ a chain of algorithms that endeavor to comprehend the intrinsic relationships for a set of data through procedures that imitate the way a human brain works. Based on the research, there are some more proposed implementations as well as the future scopes that are discussed to extrapolate the execution in different lines of businesses so that we use the technology at its\u00a0best.</p>\n<blockquote><strong><em>What is a Neural\u00a0Network?</em></strong></blockquote>\n<p>We define neural networks as a sequence of algorithms that attempt to recognize the hidden relationships in a set of data by means of imitating the way a human brain might perceive and operate based on logical reasoning. They can acclimatize to the evolving inputs so as to generate the finest possible outcome without the requirement of reshaping the output criteria. They are capable from translating texts to identifying faces, recognizing speeches to reading handwritten texts, controlling robots to a lot more that we can possibly\u00a0imagine.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/692/1*87CD2W7b8mhTYKk1Hwj5YA.jpeg\"><figcaption>Figure-1</figcaption></figure><blockquote><strong><em>Working Of Neural\u00a0Network</em></strong></blockquote>\n<p>A neural network may usually comprise multiple layers. We prefer multiple layers since each layer performs different transformations on the data that is fed as input. The input layer is described as the first layer that is responsible for picking up the input signals which are further passed on to the next layers. Every node that is present in the input layer denotes a separate feature present in the given piece of data. This input is multiplied by an assigned weight of the specific feature and fed into the next layer. All the complicated calculations and feature extraction methods are implemented on this next layer which is also termed as the hidden layer. This is responsible for finding the hidden characteristics of these input signals and gaining unknown information. Usually, there consists of more than one type of hidden layer so as to improve the performance of the model. The last layer is designated as the output layer which yields the final\u00a0result.</p>\n<p>The first layer, i.e the input layer comprises three nodes that take the input data. This input data is passed to the next layer, also termed as the hidden layer containing two nodes which are responsible for the feature extraction and other complex calculations. Finally the output of the hidden layer is fed as input to the output layer which contains the final result computed by the previous\u00a0layers.</p>\n<blockquote><strong><em>Role of Hidden\u00a0Layers</em></strong></blockquote>\n<p>It is quite obvious to interpret from Figure-1 that the hidden layers play the main role of processing the information. They act as an interface between the input and the output layers. The main calculation involved is to find the weighted sum between the input and the assigned weights. A fixed bias is added to the same and a precise activation function is selected to execute. The hidden layers can comprise multiple layers. The larger the number of hidden layers will take more time to produce the desired output. But multiple layers in the hidden layer will facilitate more complex problem solving. It is always better if we choose the optimal number of hidden layer and nodes within them. Experimental analysis has shown that we can find the ideal number of nodes required within a hidden layer is as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/684/1*DopBpw84hEs5PwdoCuGqyQ.png\"></figure><p>There is a high possibility of overfitting of data that can take place. The analysis produced may fit a given set of data so well that it may likely fail to fit in case of future observation. It may cause a reduction in the data-set\u2019s generalizability. This is where the \u2018Factor\u2019 variable comes into action in equation. It is a number ranging from 1\u201310 that is used to prevent overfitting of the\u00a0data.</p>\n<blockquote><strong><em>Activation Functions in Neural\u00a0Network</em></strong></blockquote>\n<p>Activation functions are defined as the mathematical functions in the neural network that help in determining the result. Each neuron is connected to this function and it verifies whether they should be activated or not. This is done to evaluate whether every neuron that provides the input is admissible for the model\u2019s prediction. Normalization of the output of each neuron is one of the key features of the activation function. They help in normalizing in the interval [0,1] or [-1,1]. Another characteristic of activation function is the computational efficiency. There is a technique termed as back-propagation which provides an additional computational strain on the neural networks so as to train the model. Thus the algorithmic proficiency of the activation function should be so as to effectively calculate the millions of neurons for each data\u00a0sample.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/461/1*7SMKctPEVTDOy-lMnL0_Kg.jpeg\"><figcaption>Figure-2</figcaption></figure><p>In the absence of the activation functions in neural networks, we would just have a linear regression model which would be simple to solve but cause restrictions while evaluating more complex problems such as image categorization or language translation. Thus, we use activation functions so as to implement the non-linear transformations so that we are able to solve problems concerning the higher degree polynomials. The following table discusses the various different types of activation functions that we may use while executing the neural networks.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/649/1*jQ3GL6xAKcSJIU2gW0W0kg.jpeg\"><figcaption>Figure-3</figcaption></figure><blockquote><strong><em>Advantages of Neural\u00a0Networks</em></strong></blockquote>\n<ul>\n<li>\n<strong><em>Better fault tolerance: </em></strong>In case one or more neural networks get corrupted, the result generated is not affected by it. This ensures the network is good at tolerating the\u00a0faults.</li>\n<li>\n<strong><em>Capable of working even when full knowledge is not available: </em></strong>After we train our neural networks, the result produced will possibly be inchoate and deficient. The poor performance is determined by this significance of the missing\u00a0data.</li>\n<li>\n<strong><em>Parallel Processing: </em></strong>Due to the enormous computational power of the neural network, they are able to perform multiple functions at a\u00a0time.</li>\n<li>\n<strong><em>Information is stored on the entire network: </em></strong>Data and information is stored on the network. So in case there are any bits and pieces of information that goes missing, the whole network is still able to\u00a0operate.</li>\n<li>\n<strong><em>It\u2019s ability to train the device:</em></strong> The main characteristic of the neural networks is that they learn from the events presented to them and decide accordingly. Thus it trains the machine to act or respond in a specific way depending on their past learning of similar\u00a0events.</li>\n<li>\n<strong><em>Distributed Memory:</em></strong> To get the desired output, it is necessary to make our neural network model to learn and be able to delineate the examples. The advancement of our neural network model is directly proportional to the samples that are selected.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f8a7f6153736\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<h3>The Essence of Neural\u00a0Networks</h3>\n<blockquote><strong><em>Abstract</em></strong></blockquote>\n<p>The world comprises many complex, unstructured and enormous amounts of data to compute so as to perform a network of operations over them. Humans are incapable of extricating information from compound structures. If we design a mathematical model that recreates the way a human brain is able to analyze and work, we come up with a perfect computing system that is able to solve the complicated set of data. We aim to understand the essence of the working of neural networks. They employ a chain of algorithms that endeavor to comprehend the intrinsic relationships for a set of data through procedures that imitate the way a human brain works. Based on the research, there are some more proposed implementations as well as the future scopes that are discussed to extrapolate the execution in different lines of businesses so that we use the technology at its\u00a0best.</p>\n<blockquote><strong><em>What is a Neural\u00a0Network?</em></strong></blockquote>\n<p>We define neural networks as a sequence of algorithms that attempt to recognize the hidden relationships in a set of data by means of imitating the way a human brain might perceive and operate based on logical reasoning. They can acclimatize to the evolving inputs so as to generate the finest possible outcome without the requirement of reshaping the output criteria. They are capable from translating texts to identifying faces, recognizing speeches to reading handwritten texts, controlling robots to a lot more that we can possibly\u00a0imagine.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/692/1*87CD2W7b8mhTYKk1Hwj5YA.jpeg\"><figcaption>Figure-1</figcaption></figure><blockquote><strong><em>Working Of Neural\u00a0Network</em></strong></blockquote>\n<p>A neural network may usually comprise multiple layers. We prefer multiple layers since each layer performs different transformations on the data that is fed as input. The input layer is described as the first layer that is responsible for picking up the input signals which are further passed on to the next layers. Every node that is present in the input layer denotes a separate feature present in the given piece of data. This input is multiplied by an assigned weight of the specific feature and fed into the next layer. All the complicated calculations and feature extraction methods are implemented on this next layer which is also termed as the hidden layer. This is responsible for finding the hidden characteristics of these input signals and gaining unknown information. Usually, there consists of more than one type of hidden layer so as to improve the performance of the model. The last layer is designated as the output layer which yields the final\u00a0result.</p>\n<p>The first layer, i.e the input layer comprises three nodes that take the input data. This input data is passed to the next layer, also termed as the hidden layer containing two nodes which are responsible for the feature extraction and other complex calculations. Finally the output of the hidden layer is fed as input to the output layer which contains the final result computed by the previous\u00a0layers.</p>\n<blockquote><strong><em>Role of Hidden\u00a0Layers</em></strong></blockquote>\n<p>It is quite obvious to interpret from Figure-1 that the hidden layers play the main role of processing the information. They act as an interface between the input and the output layers. The main calculation involved is to find the weighted sum between the input and the assigned weights. A fixed bias is added to the same and a precise activation function is selected to execute. The hidden layers can comprise multiple layers. The larger the number of hidden layers will take more time to produce the desired output. But multiple layers in the hidden layer will facilitate more complex problem solving. It is always better if we choose the optimal number of hidden layer and nodes within them. Experimental analysis has shown that we can find the ideal number of nodes required within a hidden layer is as\u00a0follows:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/684/1*DopBpw84hEs5PwdoCuGqyQ.png\"></figure><p>There is a high possibility of overfitting of data that can take place. The analysis produced may fit a given set of data so well that it may likely fail to fit in case of future observation. It may cause a reduction in the data-set\u2019s generalizability. This is where the \u2018Factor\u2019 variable comes into action in equation. It is a number ranging from 1\u201310 that is used to prevent overfitting of the\u00a0data.</p>\n<blockquote><strong><em>Activation Functions in Neural\u00a0Network</em></strong></blockquote>\n<p>Activation functions are defined as the mathematical functions in the neural network that help in determining the result. Each neuron is connected to this function and it verifies whether they should be activated or not. This is done to evaluate whether every neuron that provides the input is admissible for the model\u2019s prediction. Normalization of the output of each neuron is one of the key features of the activation function. They help in normalizing in the interval [0,1] or [-1,1]. Another characteristic of activation function is the computational efficiency. There is a technique termed as back-propagation which provides an additional computational strain on the neural networks so as to train the model. Thus the algorithmic proficiency of the activation function should be so as to effectively calculate the millions of neurons for each data\u00a0sample.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/461/1*7SMKctPEVTDOy-lMnL0_Kg.jpeg\"><figcaption>Figure-2</figcaption></figure><p>In the absence of the activation functions in neural networks, we would just have a linear regression model which would be simple to solve but cause restrictions while evaluating more complex problems such as image categorization or language translation. Thus, we use activation functions so as to implement the non-linear transformations so that we are able to solve problems concerning the higher degree polynomials. The following table discusses the various different types of activation functions that we may use while executing the neural networks.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/649/1*jQ3GL6xAKcSJIU2gW0W0kg.jpeg\"><figcaption>Figure-3</figcaption></figure><blockquote><strong><em>Advantages of Neural\u00a0Networks</em></strong></blockquote>\n<ul>\n<li>\n<strong><em>Better fault tolerance: </em></strong>In case one or more neural networks get corrupted, the result generated is not affected by it. This ensures the network is good at tolerating the\u00a0faults.</li>\n<li>\n<strong><em>Capable of working even when full knowledge is not available: </em></strong>After we train our neural networks, the result produced will possibly be inchoate and deficient. The poor performance is determined by this significance of the missing\u00a0data.</li>\n<li>\n<strong><em>Parallel Processing: </em></strong>Due to the enormous computational power of the neural network, they are able to perform multiple functions at a\u00a0time.</li>\n<li>\n<strong><em>Information is stored on the entire network: </em></strong>Data and information is stored on the network. So in case there are any bits and pieces of information that goes missing, the whole network is still able to\u00a0operate.</li>\n<li>\n<strong><em>It\u2019s ability to train the device:</em></strong> The main characteristic of the neural networks is that they learn from the events presented to them and decide accordingly. Thus it trains the machine to act or respond in a specific way depending on their past learning of similar\u00a0events.</li>\n<li>\n<strong><em>Distributed Memory:</em></strong> To get the desired output, it is necessary to make our neural network model to learn and be able to delineate the examples. The advancement of our neural network model is directly proportional to the samples that are selected.</li>\n</ul>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=f8a7f6153736\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["advantages","activation-functions","hidden-layers","neural-networks","neurons"]}]}